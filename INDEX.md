# TransformerLens AGI Lab - 快速访问索引

> 一键访问所有关键数据和文档

---

## 核心问题

**神经网络如何从信号流中提取特征、形成编码？**

这是一切能力的基石。不要预设任何理论正确，先观察，后假说。

---

## 最新更新 (2026-02-28)

- **GLM5路线调整**: 从"纤维丛网络"转向"特征涌现与编码机制"
- **研究方法转变**: 从理论驱动转向观察驱动
- **聚焦核心问题**: 特征如何提取、编码如何形成

---

## 进展一览

```
Gemini: DNN分析      ██████████░░░░░░░░░░ 50%  ✓ 框架完成
GPT5:   大脑机制     ██░░░░░░░░░░░░░░░░░░ 10%  ⏳ 数据缺失
GLM5:   特征涌现     █░░░░░░░░░░░░░░░░░░░  5%  🔄 方向调整
```

---

## 三条研究路线

### Gemini: DNN结构分析 (50%)

**目标**: 理解DNN特征编码机制

📁 `research/gemini/`

**核心发现**:
- 稀疏编码: 78% L0稀疏度
- 正交性: 97%
- 抽象概念占据更大空间

**快速访问**:
- [Gemini README](./research/gemini/README.md)

---

### GPT5: 大脑机制还原 (10%)

**目标**: 验证DNN机制是否存在于大脑

📁 `research/gpt5/`

**关键对比**:
| 大脑 | DNN | 差异 |
|-----|-----|------|
| ~2% 稀疏度 | ~78% | 40倍 |

**快速访问**:
- [GPT5 README](./research/gpt5/README.md)

---

### GLM5: 特征涌现与编码机制 (5%)

**目标**: 回答核心问题 - 特征如何提取、编码如何形成

📁 `research/glm5/`

**研究原则**:
1. 不预设理论正确
2. 聚焦核心问题
3. 先观察，后假说

**研究计划**:
- Phase 1: 特征涌现追踪 (1-2月)
- Phase 2: 编码基本单位分析 (2-3月)
- Phase 3: 稀疏性与正交性机制 (2-3月)

**快速访问**:
- [GLM5 README](./research/glm5/README.md)

---

## 已获得的拼图块

| 拼图块 | 数据 | 置信度 |
|-------|------|-------|
| 稀疏编码存在 | 78% L0稀疏度 | 高 |
| 高正交性 | 97% | 高 |
| 抽象层递增 | 分散度 12.6 vs 11.9 | 高 |
| 关键层识别 | Layer 2, 10, 11 | 中 |
| 复杂度驱动 | 范数 996→1990 | 高 |

---

## 缺失的拼图块

```
关键缺失:
├── 特征如何在训练中涌现？（只知道结果，不知道过程）
├── 为什么稀疏度是78%而不是50%或90%？
├── 编码的"基本单位"是什么？
├── 大脑的编码与DNN有何本质不同？
├── 局部可塑性如何产生全局稳态？
├── 特异性是如何实现的？
└── 系统性是如何实现的？
```

---

## 项目结构文件

| 文件 | 说明 |
|-----|------|
| `INDEX.md` | 本文件 - 快速索引 |
| `README.md` | 项目说明 |
| `PROJECT_STRUCTURE.md` | 详细结构说明 |

---

## 多终端协作

| 终端 | 工作目录 | 路线 | 核心任务 |
|-----|---------|------|---------|
| 终端A | `research/gemini/` | DNN结构分析 | 机制理解 |
| 终端B | `research/gpt5/` | 大脑机制还原 | 数据验证 |
| 终端C | `research/glm5/` | 特征涌现与编码 | 核心问题 |

---

## 下一步行动

### 第一优先级

```
特征涌现追踪实验 (GLM5):
├── 从随机初始化训练模型
├── 每100步记录激活状态
├── 追踪特征如何从无到有形成
└── 这是回答一切问题的基础
```

---

## 核心洞察

```
┌─────────────────────────────────────────────────────────────┐
│  大脑是自下而上的系统                                        │
│                                                             │
│  每个神经元只根据前级信号进行充电和放电                       │
│  没有中央设计者                                              │
│  通过海量数据冲刷 + 神经可塑性                               │
│  逐步形成稳定系统                                            │
│                                                             │
│  关键问题:                                                   │
│  神经网络是如何从信号流中提取特征并形成编码的？              │
│  这是一切能力的基石                                          │
│                                                             │
│  不要预设答案                                                │
│  先观察，再假说                                              │
│  完成拼图，让结构自然浮现                                    │
└─────────────────────────────────────────────────────────────┘
```
