# 深度神经网络分析还原执行文档（2026-02-20）

## 1. 执行目标

围绕“还原大脑数学结构”建立可持续研究流水线，形成三类稳定产物：

1. 结构证据：可复现、可证伪的数学结构结论。  
2. 工程证据：可运行、可扩展的系统实现。  
3. 阶段证据：可追踪的路线里程碑与时间线记录。  

---

## 2. 执行范围

1. 研究对象：语言模型、视觉模型、跨模态模型、统一路由模型。  
2. 分析路线：流形几何、动力系统、信息瓶颈、张量分解为主；拓扑验证为辅；范畴论与重整化群作为统一解释层。  
3. 数据形态：文本、视觉、指令、多模态组合、OOD测试集。  

---

## 3. 阶段计划与准入准出

## 阶段A：不变量发现（2-4周）

目标：形成候选不变量库。  
准入：至少 3 类模型 + 3 类任务 + 3 个规模点位。  
准出：

1. 候选不变量 >= 5。  
2. 跨模型稳定性 >= 0.75。  
3. 漂移均值 < 0.15。  

交付：

1. `invariant_candidates_*.json`  
2. 阶段报告与可视化截图  

## 阶段B：因果必要性（2-4周）

目标：从候选中筛出必要结构。  
准入：阶段A准出完成。  
准出：

1. 至少 2 类干预显示稳定效应。  
2. 复现率 >= 0.8。  
3. 统计显著（p-value）与效应量齐备。  

交付：

1. `causal_core_structures_*.json`  
2. 干预对照报告（包含失败样本）  

## 阶段C：最小生成重建（3-6周）

目标：最小结构复现关键能力。  
准入：阶段B存在必要结构清单。  
准出：

1. MDL压缩后保留性能 >= 80% 基线。  
2. 跨任务性能差距可解释。  
3. 至少 1 个跨模态任务通过。  

交付：

1. 最小模型定义文件  
2. 重建结果与消融报告  

## 阶段D：多模块组装（4-8周）

目标：构建“多脑区同构 + 全局工作空间”系统。  
准入：阶段C稳定。  
准出：

1. 多模态路由成功率 >= 目标阈值。  
2. 冲突收敛时延达标。  
3. 长程记忆读写稳定。  

交付：

1. 统一路由接口  
2. 系统级压测报告  

## 阶段E：开放反证与收敛（持续）

目标：保留可证伪结论并收敛到可发布知识。  
准入：阶段D具备可运行系统。  
准出：

1. 关键结论存在明确失效边界。  
2. 跨域复验通过。  
3. 风险评估与安全边界文档完成。  

交付：

1. 结论白名单/淘汰名单  
2. AGI阶段评估报告  

---

## 4. 标准实验模板（每次必须填写）

每次测试记录字段：

1. 测试目标（objective）  
2. 参数配置（params）  
3. 数据集（dataset）  
4. 测试结果（result）  
5. 分析总结（summary）  
6. 测试日期（test_date）  
7. 证据文件（artifacts）  

---

## 5. 固定 JSON Schema

```json
{
  "stage": "A|B|C|D|E",
  "test_id": "string",
  "test_date": "YYYY-MM-DD",
  "route": "fiber_bundle|transformer_baseline|hybrid_workspace|...",
  "analysis_type": "invariant_scan|causal_intervention|minimal_rebuild|...",
  "objective": "string",
  "params": {},
  "dataset": "string or object",
  "result": {},
  "summary": "string",
  "metrics": [],
  "artifacts": [],
  "evidence_score": 0.0,
  "reproducible": true,
  "limitations": [],
  "next_action": "string"
}
```

要求：

1. JSON 使用 UTF-8，禁止混用本地编码。  
2. 必须能从 JSON 反推出实验命令和参数。  
3. 每条结论至少绑定一个可访问 artifact 路径。  

---

## 6. 时间线与前端对接规范

1. 所有实验结果写入 `tempdata/agi_route_test_timeline.json`。  
2. `analysis_type` 与前端展示模块保持一一映射。  
3. 高频运行信号（如实时状态）与研究级实验分层存储，避免挤占。  
4. 前端显示以时间线为准，不手工写死测试结果。  

---

## 7. 代码与文档任务清单

## P0（立即）

1. 固化实验脚本参数模板（含 seed、层位、规模、对照组）。  
2. 补齐阶段B特征级因果测试（任务级指标）。  
3. 将新增结果写入时间线并回填“分析成果”页面。  

## P1（近两周）

1. 完成阶段C最小模型第一版。  
2. 建立阶段D统一路由原型（语言+视觉+记忆）。  
3. 建立阶段E反证任务池最小集。  

## P2（季度）

1. 扩展跨模型跨规模复验。  
2. 输出“可保留结论清单”与“失效边界清单”。  
3. 发布季度研究进度与路线评估报告。  

---

## 8. 评审与验收机制

每周评审一次，固定检查：

1. 本周新增有效证据数量。  
2. 是否出现可复现因果效应。  
3. 是否新增可证伪边界。  
4. 时间线与前端是否同步。  

月度验收：

1. 至少 1 个阶段达到准出。  
2. 至少 1 份跨模型复验报告。  
3. 至少 1 条被淘汰的错误假设（反证成果）。  

---

## 9. 风险与止损

1. 风险：实验指标只“看起来变化”，但无任务收益。  
止损：强制加入任务级指标（accuracy/loss/OOD）。  

2. 风险：结果依赖单一模型或单一seed。  
止损：多seed与跨模型复验未通过时，结论禁止升级。  

3. 风险：时间线被实时高频数据覆盖。  
止损：按 `analysis_type` 分层保留策略。  

4. 风险：文档和前端结论不一致。  
止损：所有展示从同一 JSON 证据源生成。  

---

## 10. 本执行文档的完成定义（DoD）

满足以下四项即视为执行体系落地：

1. 阶段A-E均有明确准入准出与交付清单。  
2. 每次实验都按固定 JSON 结构入库。  
3. 时间线、前端、文档三方数据一致。  
4. 每轮迭代都能明确回答：结论是什么、证据是什么、下一步是什么。  

---

## 11. 启动记录（2026-02-20）

已执行五阶段 kickoff 命令：

```bash
python scripts/start_structure_recovery_process.py --date-tag 20260220
```

产物：

1. `tempdata/structure_recovery_pipeline_kickoff_20260220.json`  
2. `tempdata/structure_recovery_pipeline_kickoff_20260220.md`  
3. `tempdata/pipeline_stage_a_invariant_20260220.json`  
4. `tempdata/pipeline_stage_b_causal_filter_20260220.json`  
5. `tempdata/pipeline_stage_c_minimal_rebuild_20260220.json`  
6. `tempdata/pipeline_stage_d_multimodal_20260220.json`  
7. `tempdata/pipeline_stage_e_open_falsification_20260220.json`  

阶段状态：

1. A 不变量发现：`pass`（stability_score=0.8416，candidate_count=19）  
2. B 因果筛选：`pass`（feature_avg_top1_uplift=0.0646，layerwise_max_uplift=0.0166）  
3. C 最小重建：`watch`（best_val_acc=0.015833，需升级为受约束最小模型）  
4. D 跨模态组装：`pass`（val_fused_acc=0.99625，synthetic 4000）  
5. E 开放反证：`pass`（已反证 H1，保留 H2，H3 open）  

时间线已新增分析类型：

1. `invariant_discovery`  
2. `causal_filtering`  
3. `minimal_reconstruction`  
4. `cross_modal_assembly`  
5. `open_falsification`  

---

## 12. Continuation Record (2026-02-20, Stage C Upgrade)

Command executed:

```bash
python scripts/scaling_validation_matrix.py --preset quick --epochs 20 --max-runs 4 --device auto --output-json tempdata/pipeline_stage_c_minimal_rebuild_20260220_v2.json --output-md tempdata/pipeline_stage_c_minimal_rebuild_20260220_v2.md
```

Result summary:

1. Stage C upgraded from `watch` to `pass`.
2. Best run: `m_1.4m__d_120k`.
3. `best_val_acc = 0.848602`.
4. Pipeline overall status updated to `pass` in:
   `tempdata/structure_recovery_pipeline_kickoff_20260220.json`.

Artifacts:

1. `tempdata/pipeline_stage_c_minimal_rebuild_20260220_v2.json`
2. `tempdata/pipeline_stage_c_minimal_rebuild_20260220_v2.md`
3. `tempdata/pipeline_stage_c_minimal_rebuild_20260220.json` (promoted stage record)
4. `tempdata/structure_recovery_pipeline_kickoff_20260220.json`
5. `tempdata/structure_recovery_pipeline_kickoff_20260220.md`

Timeline:

- Added one more `minimal_reconstruction` run entry via `ExperimentTimelineStore`.
- Current process chain A->E is active with pass/pass/pass/pass/pass states (H3 remains open).

---

## 13. Continuation Record (2026-02-20, H3 Task-Level Eval)

Commands executed:

```bash
python scripts/task_level_causal_eval.py --model-name gpt2 --layer-idx 3 --top-k 32 --alpha 0.35 --output-path tempdata/task_level_causal_eval_20260220_gpt2.json
python scripts/task_level_causal_eval.py --model-name distilgpt2 --layer-idx 3 --top-k 32 --alpha 0.35 --output-path tempdata/task_level_causal_eval_20260220_distilgpt2.json
```

Aggregate summary:

- `tempdata/task_level_causal_eval_summary_20260220.json`
- `avg_task_score_uplift = -0.00198654`
- `avg_win_rate = 0.6667`
- H3 status: `mixed_open`

Interpretation:

1. Feature-selective signal transfer to task-level score is not stable enough yet.
2. H3 remains open (mixed evidence across models).
3. Next step: expand to 100+ prompts and multi-token sequence scoring with significance tests.

Process state update:

- Pipeline status remains `pass` at stage level A/B/C/D/E.
- Stage-C is now `pass` (`best_val_acc=0.848602`, `m_1.4m__d_120k`).
- Stage-E now tracks H3 as `mixed_open`.

---

## 14. Continuation Record (2026-02-20, H3 v2 Large Task Eval)

Upgraded protocol:

1. 120 tasks per model (programmatic suite).
2. Multi-token sequence scoring (avg log-probability).
3. Sign-test p-value + bootstrap 95% CI.

Commands executed:

```bash
python scripts/task_level_causal_eval.py --model-name gpt2 --layer-idx 3 --top-k 32 --alpha 0.35 --max-tasks 120 --bootstrap-samples 2000 --output-path tempdata/task_level_causal_eval_20260220_gpt2_v2.json
python scripts/task_level_causal_eval.py --model-name distilgpt2 --layer-idx 3 --top-k 32 --alpha 0.35 --max-tasks 120 --bootstrap-samples 2000 --output-path tempdata/task_level_causal_eval_20260220_distilgpt2_v2.json
```

Model-level outcomes:

1. gpt2: uplift_logprob=0.15358481, win_rate=0.7750, p=0.0, CI=[0.08194553, 0.22669701], verdict=support_h3
2. distilgpt2: uplift_logprob=0.09942491, win_rate=0.5417, p=0.41142322, CI=[0.02022839, 0.17663442], verdict=open_h3

Aggregate outcome:

- File: `tempdata/task_level_causal_eval_summary_20260220_v2.json`
- avg_task_score_uplift_logprob=0.12650486
- avg_win_rate=0.6583
- H3 status updated to `provisional_support`

State update:

1. `tempdata/pipeline_stage_e_open_falsification_20260220.json` updated.
2. `tempdata/structure_recovery_pipeline_kickoff_20260220.json` updated.
3. Timeline appended with v2 task-level evaluation entries.

---

## 15. Continuation Record (2026-02-20, H3 v3 Multi-Model Conflict Check)

Protocol upgrade:

1. 200 tasks per model.
2. Category-level stats (`math_add`, `capital`, `antonym`, `fact`).
3. Multi-model contradiction check.

Commands executed:

```bash
python scripts/task_level_causal_eval.py --model-name distilgpt2 --layer-idx 3 --top-k 32 --alpha 0.35 --max-tasks 200 --bootstrap-samples 2000 --device auto --output-path tempdata/task_level_causal_eval_20260220_distilgpt2_v3.json
python scripts/task_level_causal_eval.py --model-name gpt2 --layer-idx 3 --top-k 32 --alpha 0.35 --max-tasks 200 --bootstrap-samples 2000 --device auto --output-path tempdata/task_level_causal_eval_20260220_gpt2_v3.json
python scripts/task_level_causal_eval.py --model-name gpt2-medium --layer-idx 8 --top-k 48 --alpha 0.30 --max-tasks 200 --bootstrap-samples 2000 --device auto --output-path tempdata/task_level_causal_eval_20260220_gpt2medium_v3.json
```

Model outcomes:

1. gpt2 -> `support_h3`
2. distilgpt2 -> `falsify_h3`
3. gpt2-medium -> `open_h3`

Aggregate outcome:

- File: `tempdata/task_level_causal_eval_summary_20260220_v3.json`
- `h3_status = mixed_conflict`
- `avg_task_score_uplift_logprob = -0.02112757`
- `avg_win_rate = 0.5533`

Category signal snapshot (cross-model average):

1. `math_add`: weak positive (`avg_uplift_logprob=0.007818`)
2. `capital`: negative (`avg_uplift_logprob=-0.19791862`)
3. `antonym`: negative (`avg_uplift_logprob=-0.35410212`)
4. `fact`: negative (`avg_uplift_logprob=-0.2917585`)

Interpretation:

- H3 is architecture/task-family sensitive at current intervention settings.
- Do not promote H3 to global support yet.
- Next iteration should adopt category-aware and model-aware intervention tuning.

---

## 16. A0 Stage Added (Encoding Genesis)

A0 has been added as a foundational stage before A:

- Stage id: `A0`
- Stage name: `encoding_genesis`
- Output: `tempdata/pipeline_stage_a0_encoding_genesis_20260220.json`
- Timeline analysis type: `encoding_genesis`

Current A0 snapshot:

1. status=`watch`
2. encoding_core_score=`0.6172`
3. major blocker=`h3_status=mixed_conflict`

Execution implication:

- Pipeline now checks `A0 -> A -> B -> C -> D -> E`.
- Overall status is `in_progress` until A0 is upgraded to pass.

Immediate next tasks for A0:

1. Add trajectory-level probes for feature-birth and stabilization.
2. Run category-aware intervention tuning (`math_add`, `capital`, `antonym`, `fact`).
3. Run cross-architecture replication to reduce model-family conflict.

---

## 17. A0 Trajectory Upgrade (2026-02-21)

New trajectory probe added and executed:

```bash
python scripts/a0_encoding_trajectory_probe.py --device auto --epochs 12 --checkpoints 1,3,6,9,12 --output tempdata/a0_encoding_trajectory_20260221.json
```

Key trajectory evidence:

1. status=`pass`
2. birth_epoch=`3`
3. first_core_score=`0.3928`
4. final_core_score=`0.7251`
5. delta_core_score=`0.3323`

A0 promotion update:

- static_core=`0.6172`
- trajectory_core=`0.7251`
- composite_core=`0.6711`
- A0 status changed from `watch` -> `pass`

Pipeline impact:

- `tempdata/structure_recovery_pipeline_kickoff_20260220.json` status changed to `pass`.
- Risk remains tracked: `Architecture-sensitive transfer conflict (H3 mixed_conflict)`.

## 18. H3 Adaptive Search Sync (2026-02-21)

New adaptive search summary has been merged into stage-E artifacts:

1. report: `tempdata/h3_category_adaptive_search_20260221.json`
2. aggregate status: `open`
3. support/falsify/open models: `1/0/2`
4. consistency score: `1.0`

Interpretation:

- Model-level falsification is no longer observed in this adaptive run.
- Evidence is improved but not yet strong enough for final promotion.
- Stage-E should remain evidence-driven with stricter significance gates.

Immediate next run:

1. increase per-category tasks from `16 -> 24`
2. keep 3-model coverage (`gpt2, distilgpt2, gpt2-medium`)
3. re-check whether status can move from `open` to stable support.

## 19. H3 Large-Sample Recheck (24/category)

Executed:

```bash
python scripts/h3_category_adaptive_search.py --models gpt2,distilgpt2,gpt2-medium --max-per-category 24 --device auto --output tempdata/h3_category_adaptive_search_20260221_v2.json
```

Result summary:

1. `status=open`
2. `support_models=0`
3. `falsify_models=0`
4. `open_models=3`

Decision:

- Keep H3 as `open` (unresolved).
- Do not promote to support yet.
- Continue with larger sample and stricter significance gates.

## 20. H3 Adaptive Search (32/category) Promotion

Executed:

```bash
python scripts/h3_category_adaptive_search.py --models gpt2,distilgpt2,gpt2-medium --max-per-category 32 --device auto --output tempdata/h3_category_adaptive_search_20260221_v3.json
```

Result summary:

1. `status=provisional_support`
2. `support_models=3`
3. `falsify_models=0`
4. `open_models=0`

Decision update:

- Promote H3 to `provisional_support`.
- Keep replication-gated policy before final support promotion.
- Stage-E artifact synced with v1/v2/v3 adaptive history.

## 21. H3 Independent-Seed Replication (32/category)

Executed:

```bash
python scripts/h3_category_adaptive_search.py --models gpt2,distilgpt2,gpt2-medium --max-per-category 32 --seed 20260222 --device auto --output tempdata/h3_category_adaptive_search_20260221_v3_replica_seed20260222.json
```

Replication outcome:

1. `status=provisional_support`
2. `support_models=2`
3. `falsify_models=0`

Joint view over two 32/category runs:

- replicated provisional support achieved
- support_models range: `2..3`
- no model-level falsification observed

Operational decision:

- Keep H3 as `provisional_support` with replication tag.
- Move next focus to holdout-task replication and template generalization checks.

## 22. H3 Third-Seed Replication (32/category)

Executed:

```bash
python scripts/h3_category_adaptive_search.py --models gpt2,distilgpt2,gpt2-medium --max-per-category 32 --seed 20260223 --device auto --output tempdata/h3_category_adaptive_search_20260221_v3_replica_seed20260223.json
```

Outcome:

1. `status=provisional_support`
2. `support_models=3`
3. `falsify_models=0`

Replication summary over 3 seeds at 32/category:

- all runs: `provisional_support`
- support_models range: `2..3` (avg `2.67`)
- no model-level falsification

Decision:

- mark H3 as `provisional_support_replicated`
- advance to holdout-task and template-generalization phase

## 23. H3 Holdout Validation (Unseen Templates)

Executed:

```bash
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --max-per-category 24 --seed 20260221 --device auto --output tempdata/h3_holdout_validation_20260221.json
```

Outcome:

1. `status=open`
2. `support_models=1`
3. `falsify_models=0`
4. `open_models=2`

Decision revision:

- In-pool replication remains positive.
- Holdout generalization is still unresolved.
- Keep final H3 stage verdict as `open` until holdout replication passes.

## 24. H3 Holdout Upscale Recheck (32/category)

Executed:

```bash
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --max-per-category 32 --seed 20260222 --device auto --output tempdata/h3_holdout_validation_20260221_v2_seed20260222.json
```

Outcome:

1. `status=open`
2. `support_models=0`
3. `falsify_models=0`
4. `open_models=3`

Stage-E strict conclusion:

- In-pool evidence is replicated.
- Holdout evidence remains open.
- Final H3 verdict stays `open` until holdout replication improves.

## 25. Leakage-Control Upgrade (No-Leak + Locked Holdout)

Implemented:

1. `scripts/h3_category_adaptive_search.py`
   - tune/eval split added for per-category config selection and reporting.
2. `scripts/h3_holdout_validation.py`
   - holdout now uses locked in-pool configs, no holdout retuning.

New evidence:

- in-pool no-leak: `tempdata/h3_category_adaptive_search_20260221_v4_noleak_seed20260224.json`
  - `status=provisional_support`, `support_models=2`, `falsify_models=0`
- locked holdout:
  - `tempdata/h3_holdout_validation_20260221_v3_locked_seed20260225.json`
  - `tempdata/h3_holdout_validation_20260221_v4_locked_seed20260226.json`
  - both `status=open`, `support_models=0`, `open_models=3`

Stage-E decision remains:

- H3 = `open` (pending holdout generalization replication).

## 26. Expanded Locked Holdout (3 New Seeds)

Purpose:

- stress-test holdout generalization under harder and broader templates
- keep strict no-retune protocol via locked in-pool configs

Executed:

```bash
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --task-profile expanded --max-per-category 48 --seed 20260227 --locked-configs-from tempdata/h3_category_adaptive_search_20260221_v4_noleak_seed20260224.json --fallback-config-index 1 --device auto --output tempdata/h3_holdout_validation_20260221_v5_locked_expanded_seed20260227.json
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --task-profile expanded --max-per-category 48 --seed 20260228 --locked-configs-from tempdata/h3_category_adaptive_search_20260221_v4_noleak_seed20260224.json --fallback-config-index 1 --device auto --output tempdata/h3_holdout_validation_20260221_v6_locked_expanded_seed20260228.json
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --task-profile expanded --max-per-category 48 --seed 20260229 --locked-configs-from tempdata/h3_category_adaptive_search_20260221_v4_noleak_seed20260224.json --fallback-config-index 1 --device auto --output tempdata/h3_holdout_validation_20260221_v7_locked_expanded_seed20260229.json
```

Results:

1. all three runs remain `open`
2. no model-level falsification, but no stable support pattern either
3. accumulated locked-holdout replication remains `open_not_yet_generalized`

Decision:

- Stage-E H3 verdict remains `open`
- next promotion gate remains holdout replication, not in-pool performance

## 27. Strict Single-Config Holdout (Per-Model-One-Config)

Goal:

- test whether a model can transfer with one fixed intervention config across all categories

Executed:

```bash
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --task-profile expanded --max-per-category 48 --lock-mode per_model_single --seed 20260230 --locked-configs-from tempdata/h3_category_adaptive_search_20260221_v4_noleak_seed20260224.json --fallback-config-index 1 --device auto --output tempdata/h3_holdout_validation_20260221_v8_singlecfg_expanded_seed20260230.json
python scripts/h3_holdout_validation.py --models gpt2,distilgpt2,gpt2-medium --task-profile expanded --max-per-category 48 --lock-mode per_model_single --seed 20260231 --locked-configs-from tempdata/h3_category_adaptive_search_20260221_v4_noleak_seed20260224.json --fallback-config-index 1 --device auto --output tempdata/h3_holdout_validation_20260221_v9_singlecfg_expanded_seed20260231.json
```

Results:

1. both runs remain `open`
2. both runs show `falsify_models=1`
3. strict holdout verdict: `single_config_fragile`

Decision:

- keep H3 at `open`
- block promotion under strict transfer gate until falsification risk is removed

## 28. Strict Failure Localization (Single-Config)

New tool:

- `scripts/h3_failure_localizer.py`
- report: `tempdata/h3_failure_localization_20260221_v1_singlecfg.json`

Input strict runs:

1. `tempdata/h3_holdout_validation_20260221_v8_singlecfg_expanded_seed20260230.json`
2. `tempdata/h3_holdout_validation_20260221_v9_singlecfg_expanded_seed20260231.json`

Localization summary:

1. status=`fragile_single_config`
2. persistent strict-failure clusters=`4`
3. dominant failure categories=`math_add`, `fact`
4. representative clusters:
   - `gpt2::fact_holdout`
   - `gpt2::math_add_holdout`
   - `distilgpt2::math_add_holdout`

Decision impact:

- H3 remains `open`.
- Promotion blocked until strict failure clusters are reduced/removed.

## 29. Gating Adapter Experiment (Strict Single-Config)

Implementation update:

- `scripts/h3_holdout_validation.py` now supports failure-driven adapter modes:
  - `--adapter-failure-report`
  - `--adapter-profile` (`none|conservative|math_fact_relief|math_fact_strong`)
  - `--adapter-strength`

Main runs:

- conservative: `v10`, `v11`
- math_fact_relief: `v12`, `v13`
- math_fact_strong: `v14`, `v15`, `v16`, `v17`

Observed effect:

1. baseline avg falsify_models: `1.0`
2. strong adapter avg falsify_models: `0.25`
3. strict failure clusters reduced: `4 -> 2`

But:

- single-config fragility still exists
- one run reaches `mixed_conflict`
- final H3 verdict remains `open`

Decision:

- keep adapter as mitigation, not as proof of resolution
- keep strict gate: require single-config falsify_models_max = 0 across replicated seeds

## 30. Neutralize-Failures Adapter (Strict Gate)

New profile:

- `neutralize_failures` in `scripts/h3_holdout_validation.py`
- objective: suppress strict-failure regressions under per-model-single-config transfer

Runs:

- `v20`, `v21`, `v22` (expanded, 48/category, seeds 20260305~20260307)

Outcome:

1. average falsify_models reduced to `0.3333`
2. strict failure clusters reduced from `4` to `1`
3. residual cluster: `gpt2-medium::math_add_holdout`

Decision:

- mitigation confirmed, full closure not yet achieved
- keep H3 as `open`
- next action focuses only on residual math_add cluster

## 31. Residual-Cluster Containment Pilot (gpt2-medium math_add)

Approach:

- apply `math_quarantine` adapter in strict single-config mode
- objective is containment of persistent falsification, not immediate capability gain

Runs:

- `..._seed20260311.json`
- `..._seed20260312.json`
- `..._seed20260313.json`

Observed:

1. model-level falsification removed in all 3 runs (`falsify_models=0`)
2. math_add verdict moved to `open` with near-zero uplift
3. failure localization report (`v5`) shows `strict_failure_cluster_count=0`

Interpretation:

- containment works
- this is not yet a positive-transfer fix
- H3 remains `open` pending constructive repair

## 32. Hybrid Constructive v1 (Strict Multi-Seed)

Design:

- constructive override on residual cluster (`gpt2-medium::math_add`)
- neutralize fallback for remaining fragile zones

Runs:

- `v23_hybridconstructive_seed20260314/15/16`

Observed:

1. strict model-level falsification removed in all three runs (`falsify_models=0`)
2. support remains limited (`support_models_max=1`)
3. strict failure clusters reduced to zero in localization report `v6`

Decision:

- major stability improvement achieved
- promotion gate still not satisfied due insufficient support breadth
- final H3 verdict remains `open`

## 33. Hybrid Support Boost v2/v3 (Strict Multi-Seed Extension)

Goal:

- keep strict anti-falsification behavior
- increase support breadth under `per_model_single` lock mode

Runs:

- `v25_hybridsupportv2_seed20260320/21/22`
- `v26_hybridsupportv3_seed20260323/24/25`

Observed:

1. both profiles keep `falsify_models_max=0`
2. both profiles remain `support_models_avg=0.3333`, `support_models_max=1`
3. strict failure localization stays cleared (`v7`, cluster_count=0)

Interpretation:

- risk control is stable and reproducible
- support breadth bottleneck is now the dominant blocker, not strict failure clusters

Decision:

- keep H3 as `open` under strict gate
- next experiments should target support-category expansion while preserving `falsify_models_max=0`

## 34. gpt2 math_add Constructive Search + Hybrid v4

Goal:

- convert one recurrent `open` bucket into stable support without reintroducing strict falsification

Step A (search):

- run targeted search report: `tempdata/h3_gpt2_mathadd_constructive_search_20260222.json`
- best candidate: `layer=3, top_k=16, alpha=0.25, t=1.0`
- search/validate seeds both show support and zero falsify

Step B (integration):

- add profile `hybrid_support_boost_v4` in `scripts/h3_holdout_validation.py`
- integrate gpt2 math_add constructive config with existing strict safety rules

Step C (strict multi-seed):

- `v27` runs (`seed20260326/27/28`)
- all runs keep `falsify_models=0`
- support breadth remains limited (`support_models=0/1/0`)

Decision:

- strict safety continues to hold
- support breadth remains the primary blocker
- H3 stays `open`

## 35. distilgpt2 capital Constructive Search + Hybrid v5

Goal:

- break strict support bottleneck (`support_models_max=1`) while keeping `falsify_models_max=0`

Step A (search):

- run `tempdata/h3_distilgpt2_capital_constructive_search_20260222.json`
- best config: `layer=1, top_k=24, alpha=0.20, t=1.0`
- search/validate both support with zero falsify

Step B (integration):

- add profile `hybrid_support_boost_v5` in `scripts/h3_holdout_validation.py`
- combine:
  - gpt2 math_add constructive config
  - distilgpt2 capital constructive config
  - gpt2-medium math_add constructive config
  - strict neutralize fallback for failure targets

Step C (strict multi-seed):

- `v28` runs (`seed20260329/30/31`)
- results:
  - support_models = `2/2/1`
  - falsify_models = `0/0/0`
  - average support_models = `1.6667`

Decision:

- strict gate has moved to near-support level
- keep H3 as `open_pending_replication` until one more fresh seed block confirms consistency

## 36. v5 Second Block Replication (Seeds 20260401-20260403)

Goal:

- verify whether v5 provisional-support pattern is stable on a fresh seed block

Runs:

- `v29_hybridsupportv5_seed20260401/02/03`

Observed:

1. support_models = `1/2/1`
2. falsify_models = `0/0/0`
3. block summary: support_avg=`1.3333`, support range=`[1,2]`

Combined with v28 (six seeds total):

1. support_avg=`1.5`
2. status counts: `provisional_support=3`, `open=3`
3. strict failure clusters remain zero (`v11` localization)

Decision:

- maintain H3 status as `near_support_stable_but_not_fully_replicated`
- do not upgrade to full provisional support yet

## 37. v30 Baseline + gpt2 Category Calibration Search

Goal:

- validate v5 on a fresh block before introducing new calibration

Runs:

- `v30_hybridsupportv5_seed20260404/05/06`

Observed:

1. support_models = `2/1/1`
2. falsify_models = `0/0/0`
3. v5 remains near-support but with support-floor still at 1

Calibration actions:

1. `gpt2::antonym` search  
   - report: `tempdata/h3_gpt2_antonym_constructive_search_20260222.json`
   - best: `layer=6, top_k=32, alpha=0.25`
2. `gpt2::capital` search  
   - report: `tempdata/h3_gpt2_capital_constructive_search_20260222.json`
   - best: `layer=4, top_k=32, alpha=0.25`

Decision:

- proceed to v6 integration with both gpt2 calibrations

## 38. Hybrid v6 Replication (Seeds 20260407-20260412)

Goal:

- improve support stability while preserving strict no-falsify guarantee

Integration:

- add profile `hybrid_support_boost_v6` in `scripts/h3_holdout_validation.py`
- include calibrated gpt2 capital/antonym configs from section 37

Block 1 (`v31`, seeds 20260407/08/09):

1. support_models = `1/2/2`
2. falsify_models = `0/0/0`
3. summary: support_avg=`1.6667`

Block 2 (`v32`, seeds 20260410/11/12):

1. support_models = `1/2/2`
2. falsify_models = `0/0/0`
3. summary: support_avg=`1.6667`

Merged v31+v32 (six seeds):

1. support_avg=`1.6667`, support_range=`[1,2]`
2. status counts: `provisional_support=4`, `open=2`
3. strict failure clusters remain zero (`v13` localization)

Decision:

- v6 improves stability vs v5
- H3 remains `open_pending_replication` until support-floor reaches 2 on a fresh block
